{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import onnx\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ExampleModel, self).__init__()\n",
    "\n",
    "    def forward(self, u, U, X):\n",
    "        U1 = torch.concat((U, u))\n",
    "        U1 = U1[1:, :]\n",
    "        x = X[-1:, :] + torch.sum(u)\n",
    "        X1 = torch.concat((X, x))\n",
    "        X1 = X1[1:, :]\n",
    "        return x, X1, U1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[6., 6., 6.]]), tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [6., 6., 6.]]), tensor([[9., 9., 9., 9., 9.],\n",
      "        [8., 8., 8., 8., 8.],\n",
      "        [7., 7., 7., 7., 7.],\n",
      "        [6., 6., 6., 6., 6.],\n",
      "        [5., 5., 5., 5., 5.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [3., 3., 3., 3., 3.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [1., 1., 1., 1., 1.]]))\n"
     ]
    }
   ],
   "source": [
    "FEATURES = 5\n",
    "TARGETS = 3\n",
    "T = 10\n",
    "# Create three tensors\n",
    "u = torch.ones((1, FEATURES))\n",
    "U = torch.ones((T - 1, FEATURES)) * torch.arange(T, 1, -1).unsqueeze(1)\n",
    "X = torch.ones(T, TARGETS)\n",
    "\n",
    "# Create the model\n",
    "model = ExampleModel()\n",
    "\n",
    "# Run the model\n",
    "output = model(u, U, X)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%u : Float(1, 5, strides=[5, 1], requires_grad=0, device=cpu),\n",
      "      %U : Float(9, 5, strides=[5, 1], requires_grad=0, device=cpu),\n",
      "      %X : Float(10, 3, strides=[3, 1], requires_grad=0, device=cpu)):\n",
      "  %/Concat_output_0 : Float(10, 5, strides=[5, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=0, onnx_name=\"/Concat\"](%U, %u), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:7:0\n",
      "  %/Constant_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant\"](), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:8:0\n",
      "  %/Constant_1_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_1\"](), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:8:0\n",
      "  %/Constant_2_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/Constant_2\"](), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:8:0\n",
      "  %/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_3\"](), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:8:0\n",
      "  %U1 : Float(9, 5, strides=[5, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/Slice\"](%/Concat_output_0, %/Constant_1_output_0, %/Constant_2_output_0, %/Constant_output_0, %/Constant_3_output_0), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:8:0\n",
      "  %/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_4\"](), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:9:0\n",
      "  %/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_5\"](), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:9:0\n",
      "  %/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/Constant_6\"](), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:9:0\n",
      "  %/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_7\"](), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:9:0\n",
      "  %/Slice_1_output_0 : Float(1, 3, strides=[3, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/Slice_1\"](%X, %/Constant_5_output_0, %/Constant_6_output_0, %/Constant_4_output_0, %/Constant_7_output_0), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:9:0\n",
      "  %/ReduceSum_output_0 : Float(requires_grad=0, device=cpu) = onnx::ReduceSum[keepdims=0, onnx_name=\"/ReduceSum\"](%u), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:9:0\n",
      "  %x : Float(1, 3, strides=[3, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add\"](%/Slice_1_output_0, %/ReduceSum_output_0), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:9:0\n",
      "  %/Concat_1_output_0 : Float(11, 3, strides=[3, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=0, onnx_name=\"/Concat_1\"](%X, %x), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:10:0\n",
      "  %/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_8\"](), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:11:0\n",
      "  %/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_9\"](), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:11:0\n",
      "  %/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/Constant_10\"](), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:11:0\n",
      "  %/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_11\"](), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:11:0\n",
      "  %X1 : Float(10, 3, strides=[3, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/Slice_2\"](%/Concat_1_output_0, %/Constant_9_output_0, %/Constant_10_output_0, %/Constant_8_output_0, %/Constant_11_output_0), scope: __main__.ExampleModel:: # /tmp/ipykernel_9061/1201402997.py:11:0\n",
      "  return (%x, %X1, %U1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"example4\"\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Save the model in ONNX format\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (u, U, X),\n",
    "    f\"{model_name}.onnx\",\n",
    "    verbose=True,\n",
    "    input_names=[\"u\", \"U\", \"X\"],\n",
    "    output_names=[\"x\", \"X1\", \"U1\"],\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "onnx_model = onnx.load(f\"{model_name}.onnx\")\n",
    "\n",
    "# Check the model\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Add description to the model\n",
    "onnx_model.graph.doc_string = \"Example to test FMU with local variables.\"\n",
    "\n",
    "# Add metadata to the model\n",
    "onnx_model.producer_name = \"ExampleModel\"\n",
    "onnx_model.producer_version = \"0.0.1\"\n",
    "onnx_model.domain = \"example\"\n",
    "onnx_model.model_version = 1\n",
    "\n",
    "# Save the model\n",
    "onnx.save(onnx_model, f\"{model_name}.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating model description\n",
    "\n",
    "Create and save the model description to be provided to ONNX2FMU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_description = {\n",
    "    \"name\": \"example2\",\n",
    "    \"description\": \"Example to test FMU with local variables.\",\n",
    "    \"FMIVersion\": \"2.0\",\n",
    "    \"inputs\": [\n",
    "        {\n",
    "            \"name\": \"u\",\n",
    "            \"description\": \"A vector of control variables at time t.\"\n",
    "        },\n",
    "    ],\n",
    "    \"outputs\": [\n",
    "        {\n",
    "            \"name\": \"x\",\n",
    "            \"description\": \"The state of the system at time t+1.\"\n",
    "        }\n",
    "    ],\n",
    "    \"locals\": [\n",
    "        {\n",
    "            \"nameIn\": \"X\",\n",
    "            \"nameOut\": \"X1\",\n",
    "            \"description\": \"The history of states from t-N to t.\"\n",
    "        },\n",
    "        {\n",
    "            \"nameIn\": \"U\",\n",
    "            \"nameOut\": \"U1\",\n",
    "            \"description\": \"The history of control variables frmo t-N to t-1.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save model description\n",
    "with open(f\"{model_name}Description.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(model_description, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating input file and output for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 100\n",
    "U_hist = np.ones((time_steps, FEATURES)) * np.arange(time_steps)[:, None] + 1\n",
    "columns = [f\"u_0_{i}\" for i in range(FEATURES)]\n",
    "df = pd.DataFrame(\n",
    "    data=U_hist,\n",
    "    columns=columns,\n",
    "    index=pd.Index(data=np.arange(time_steps), name='time')\n",
    ").to_csv(f\"input.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hy2rome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
